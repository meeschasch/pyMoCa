#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Jul 25 18:49:00 2021

@author: mischasch

TODO:
    - units (check)
    - properties for simulation (e.g. P-Fälle, savefigs etc.)
    - parameter and result inherit from "element" (nicht sinnvoll?)
"""

#imports
import pandas as pd, scipy.stats as stats, numpy as np, re, math, os
import matplotlib.pyplot as plt, seaborn as sns, pickle, warnings
from pathlib import Path
from matplotlib import style

#plot presets
#plt.rcParams.update({'font.size': 14})ß
plt.rcParams.update({'figure.dpi': 100})
plt.rcParams.update({'legend.loc': 'best'})
style.use('seaborn')


class Param:
    def __init__(self, name, dist = None, hist_data = None, s = None, unit = '-'):
        """
        Creates a new object of the Param class

        Parameters
        ----------
        name : String
            Name of the parameter
        dist (optional) : scipy.stats
            Distribution of this parameter
        hist_data (optional): one-dimensional numpy array of numbers
            Historical data of the parameter
        s: one-dimensional numpy array of numbers
            Input data used for simulation (usually generated by self.realise, but could be passed as initiating parameter)
        unit: physical unit (string). Default is -.    
    
Returns
        -------
        None.

        """
        if (hist_data is not None) & (not isinstance(hist_data, np.ndarray)):
            raise ValueError('hist_data is no numpy array')
        
        self.name = name
        self.dist = dist
        self.hist_data = hist_data
        self.s= s
        self.unit = unit
        
        
    def plot(self, mode = 'dhs', showfig = True):
        """
        creates and shows a plot of the parameter. In any case, the theoretical PDF of the distribution is displayed. 
        If available, historical data as well as randomly drawn data for the MC simulation is displayed.

        Parameters
        ----------
        mode : string
            Plots the parameter. Default: 'd'. The submitted string can be a combination of the followiung characters:
            'd': distribution
            'h': historic data
            's': simulation data
        showfig: If True, plot is showed
            
        Returns
        -------
        None.

        """
        
        #cehck whether mode is valid
        if re.search('[^dhs]', mode) is not None:
            raise ValueError('mode string contains characters other than dhs')
        
        fig, ax = plt.subplots()
        fig.set_size_inches(5.51, 3.9)  # 2*14 cm breit
        
    
        
        if self.hist_data is not None:
            xmin = min(min(self.hist_data), self.dist.ppf(0.01)) * 0.9
            xmax = max(max(self.hist_data), self.dist.ppf(0.99)) * 1.1
        elif self.dist is not None:
            xmin = self.dist.ppf(0.01) * 0.9
            xmax = self.dist.ppf(0.99) * 1.1
        else:
            xmin = min(self.s) * 0.9
            xmax = max(self.s) * 1.1
                
        
        x = np.linspace(xmin, xmax, 100)
        #nbins = 100
        
        #print distribution
        if 'd' in mode:
            #pdf
            if self.dist is not None:
                ax.plot(x, self.dist.pdf(x), color = 'lightcoral', lw = 2, label = 'fit')
           
        #print historical data
        if (self.hist_data is not None)& ('h' in mode):
           #histogram
           ax.hist(self.hist_data, alpha=0.9, density=True, color = 'blue', label = 'observed')
           
        #print simulation data
        if (self.s is not None) & ('s' in mode):
            ax.hist(self.s, alpha=0.2, density=True, color = 'firebrick', label = 'simulation')
            
        #plot 80% CI for dist and hist_data
        ylim = plt.ylim()
        
        if (self.dist is not None) &('d' in mode):
            #80%CI fit
            ax.hlines(ylim[1]*1.1, xmin = self.dist.ppf(0.1), xmax = self.dist.ppf(0.9), label = 'min, P90, mean, P10, max - sim.', color = 'lightcoral', linewidth = 3)
            ax.hlines(ylim[1]*1.1, xmin = self.dist.ppf(0.0001), xmax = self.dist.ppf(0.9999), color = 'lightcoral', linewidth = 3, linestyle = '--')
            p = [self.dist.ppf(0.0001),
                 self.dist.ppf(0.1),
                 self.s.mean(),
                 self.dist.ppf(0.9),
                 self.dist.ppf(0.9999)]
            ax.scatter(p, np.ones(len(p)) * ylim[1]*1.1, edgecolors = 'lightcoral', c = 'None', linewidths = 2)
        
        if (self.hist_data is not None)& ('h' in mode):
            #80% CI historical data
           ax.hlines(ylim[1]*1.2, xmin = np.quantile(self.hist_data, 0.1), xmax = np.quantile(self.hist_data, 0.9), label = 'min, P90, mean, P10, max - obs.', color = 'blue',  linewidth = 3)
           ax.hlines(ylim[1]*1.2, xmin = self.hist_data.min(), xmax = self.hist_data.max(), color = 'blue',  linewidth = 3, linestyle = '--')

           p = [self.hist_data.min(),
                np.quantile(self.hist_data, 0.1),
                self.hist_data.mean(),
                np.quantile(self.hist_data, 0.9),
                self.hist_data.max()]
           ax.scatter(p, np.ones(len(p)) * ylim[1]*1.2, edgecolors = 'blue', c = 'None', linewidths = 2)
            
        ax.set_title(f"Parameter: {self.name} [{self.unit}]")
        ax.set_xlim(xmin, xmax)
        #ax.legend(loc = (1.04,0.5), frameon = True)
        ax.grid(True)
        
        #if showfig:
         #   plt.show()
        
        return fig
            
    @property
    def summary(self):
        return self.__summary()
    
    def __summary(self):
        """
        compiles a summary table conatining a statistical description of the input parameter.
        If available, balso the historical data is described.

        Returns
        -------
        pandas.DataFrame containing the description

        """

        # create pd.DataFrame for table
        indexs = ['n / fit', 'unit', 'mean', 'std', 'min', 'max', 'P10', 'P50', 'P90']
                
        t= pd.DataFrame(index = indexs)
    
        #fill values for the parameter distribution
        if self.dist is not None:
            t.loc['n / fit', 'fit'] = self.dist.dist.name
            t.loc['mean', 'fit'] = self.dist.mean()
            t.loc['std', 'fit'] = self.dist.std()
            t.loc['min', 'fit'] = self.dist.ppf(0)
            t.loc['max', 'fit'] = self.dist.ppf(1)
            t.loc['P90', 'fit'] = self.dist.ppf(0.1)
            t.loc['P50', 'fit'] = self.dist.ppf(0.5)
            t.loc['P10', 'fit'] = self.dist.ppf(0.9)
        
        #fill values for the historical data
        if self.hist_data is not None:
           #t['data'] = t.loc[:,'fit'] #create column for data
           t.loc['mean','data'] = np.mean(self.hist_data)
           t.loc['std','data'] = np.std((self.hist_data))
           t.loc['min','data'] = min(self.hist_data)
           t.loc['max','data'] = max(self.hist_data)
           t.loc['n / fit','data'] = self.hist_data.size
           t.loc['P90','data'] = np.quantile(self.hist_data, 0.1)
           t.loc['P50','data'] = np.quantile(self.hist_data, 0.5)
           t.loc['P10','data'] = np.quantile(self.hist_data, 0.9)

        #fill values for the simulation data
        if self.s is not None:
           #t['sim'] = t.loc[:,'fit'] #create column for data
           t.loc['mean','sim'] = np.mean(self.s)
           t.loc['std','sim'] = np.std((self.s))
           t.loc['min','sim'] = min(self.s)
           t.loc['max','sim'] = max(self.s)
           t.loc['n / fit','sim'] = self.s.size
           t.loc['P90','sim'] = np.quantile(self.s, 0.1)
           t.loc['P50','sim'] = np.quantile(self.s, 0.5)
           t.loc['P10','sim'] = np.quantile(self.s, 0.9)
           
        t.loc['unit', :] = self.unit
           
        return t.transpose()
            
    def realise(self, nmc, overwrite_existing = False):
        """
        Draws nmc numbers of the parameters distribution and sets the set as self.s

        Parameters
        ----------
        nmc : int
            numnber of realisations (must be >= 1)
        overwrite_existing: If True, existing simulation data will be overwritten. Default: False.

        Returns
        -------
        0 if succesful, if nmc <1 1, the function returns -1.

        """
        if nmc < 1:
            raise ValueError('Number of realisations is too small')
        
        if (self.s is None) | ((self.s is not None) & (overwrite_existing)):
            try:
                self.s = self.dist.rvs(size = nmc)
            except:
                raise Exception('Realisation failed')
        
    
class Result:
    def __init__(self, name, s, unit = '-'):
        """
        Creates a new object of the Result class.

        Parameters
        ----------
        name : Tstring
            name of the result
        s : numerical array
            result values
        unit: string
            physical unit
            

        Returns
        -------
        None.

        """
        self.name = name
        self.s = s
        self.unit = unit
        
    def plot(self, showfig = True):
        """
        plots the result

        Returns
        -------
        None.

        """
        
        xmin = min(self.s) * 0.9
        xmax = max(self.s) * 1.1
        fig, ax = plt.subplots()
        fig.set_size_inches(5.51, 3.9)  # 2*14 cm breit
        
        #histogram
        ax.hist(self.s, alpha=0.9, density=True, label = 'modelled', color = 'forestgreen')
        
        #80%CI
        ylim = plt.ylim()
        ax.hlines(ylim[1]*1.1, xmin = np.quantile(self.s, 0.1), xmax = np.quantile(self.s, 0.9), label = 'min, P90, mean, P10, max', color = 'forestgreen', linewidth= 3, alpha = 0.9)       
        ax.hlines(ylim[1]*1.1, xmin = self.s.min(), xmax = self.s.max(), color = 'forestgreen', linewidth= 3, alpha = 0.9, linestyle = '--')       

        p = [self.s.min(),
             np.quantile(self.s, 0.1),
             self.s.mean(),
             np.quantile(self.s, 0.9),
             self.s.max()]
        ax.scatter(p, np.ones(len(p)) * ylim[1]*1.1, edgecolors = 'forestgreen', c = 'None', linewidths = 2)
        
        ax.set_title(f"Result: {self.name} [{self.unit}]")
        ax.set_xlim(xmin, xmax)
        #ax.legend(loc = (1.04,0.5), frameon = True)
        ax.grid(True)
        
        #if showfig:
         #   plt.show()
        
        plt.close()
        
        return fig
        
    @property
    def summary(self):
        return self.__summary()
    
    
    def __summary(self):
        """
        compiles a summary table conatining a statistical description of the result.

        Returns
        -------
        pandas.DataFrame containing the description

        """

        # create pd.DataFrame for table
        indexs = ['n', 'unit', 'mean', 'std', 'min', 'max', 'P90', 'P50', 'P10']
                
        t= pd.DataFrame(columns = ['result'], index = indexs)
    
        
        t.loc['mean','result'] = np.mean(self.s)
        t.loc['std','result'] = np.std((self.s))
        t.loc['min','result'] = min(self.s)
        t.loc['max','result'] = max(self.s)
        t.loc['n','result'] = self.s.size
        t.loc['P90','result'] = np.quantile(self.s, 0.1)
        t.loc['P50','result'] = np.quantile(self.s, 0.5)
        t.loc['P10','result'] = np.quantile(self.s, 0.9)
        t.loc['unit', 'result'] = self.unit
           
        return t.transpose()
    
    def evaluateConvergence(self):
        """
        evaluates the convergence of a result by computing and setting the attributes self.runningAverage and 
        self.runningStandardError. 

        Returns
        -------
        None.

        """
        #check ihf simulation data is available
        if self.s is None:
            raise Exception('No simulated data available to analyse')
        
        self.runningAverage = runningAverage(self.s)
        self.runningStandardError = runningStandardError(self.s)
        
        print('Parameter: {} ... Standard Error of the mean after the last iteration is {:.2f} or {:.2f} %%'
              .format(self.name, self.runningStandardError[-1],
                      self.runningStandardError[-1] / self.runningAverage[-1]*100))
                
        
class Simulation:
    def __init__(self, name, saveplots = True, nmc = 100, savedir = ''):
        """
        creates a new simulation object.

        Parameters
        ----------
        name : string
            name of the simulation
        nmc: int
            number of realisations
        safedir: Path to where plots are stored. Leave blank if 
        safeplots: If True, all generated plots are saved in savedir

        Returns
        -------
        None.

        """
        #self.name = name
        self.__parameters = []
        self.__results = []

        
        #dictionary with all necessary settings
        self.settings = {
            'name': name,
            'nmc': nmc,
            'savedir': savedir,
            'saveplots': saveplots}
        
        if savedir != '': 
            self.__create_savedirs() #create structure of directories to save plots
        
    def __getitem__(self, index):
        '''
        lets the user access parameters and result of a simulation using simulation_name[attribute name]
        '''
        if index in self.parameter_names:
            for param in self.__parameters:
                if param.name == index:
                    return param
        elif index in self.result_names:
            for result in self.__results:
                if result.name == index:
                    return result
        else:
            raise ValueError(index + ' not in parameters or results')
            
    def __setitem__(self, key, newvalue):
        #only continue if new item is a result or a paraeter
        if not isinstance(newvalue, (Param, Result)):
            raise ValueError('New item must bei either a parameter or a result')
         
        #adding new elements using __setitem__ not allowed
        if newvalue.name not in self.__parameters + self.__results:
            raise ValueError('Use addParameter() or addResult() to add new elements')
            
        if isinstance(newvalue, Param): #it's a parameter
            #remove existing entry
            if key in self.parameter_names: #parameter already exists
                for par in self.__parameters:
                    if par.name == key:
                        warnings.warn('Parameter already exsists and is replaced with the new one')
                        self.__parameters.remove(par) #remove existing parameter
            
                #add new
                self.__parameters.append(newvalue)
            
        elif isinstance(newvalue, Result):
            #remove existing entry
            if key in self.result_names:
                for res in self.__results:
                    if res.name == key:
                        warnings.warn('Result already exsists and is replaced with the new one')
                        self.__results.remove(res)
            
                #add new
                self.__results.append(newvalue)

            
        
            
    def __create_savedirs(self):
        dirs = ['parameters', 'results', 'qc and sensitivity']
        
        for diri in dirs:
            path = self.settings['savedir'] / diri
            if not os.path.isdir(path):
                os.makedirs(path)
        
        
    def set_savedir(self, savedir):
        self.settings['savedir'] = Path(savedir)
        self.__create_savedirs()
        
        return
    
    #properties
    @property
    def parameter_names(self):
        return [par.name for par in self.__parameters]
    
    @property
    def result_names(self):
        return [res.name for res in self.__results]
    
    @property
    def summary(self):
        return self.__summary()
    
    def addParameter(self, param):
        """
        add a parameter to the simulation.

        Parameters
        ----------
        param : mcoo.Param
            Dthe parameter

        Returns
        -------
        None

        """
        #check if param is an mcoo.Param object
        if not isinstance(param, Param):
            raise ValueError('Parameter is not an mcoo.Param object')
        
        #check if already exists
        if param.name in self.result_names + self.parameter_names:
            raise ValueError('Element of that name already present')
        
        self.__parameters.append(param)
        
        
        
    def realiseParameterSets(self, overwrite_existing = False):
        """
        draws nmc values of the distribution of each parameter. 

        Parameters
        ----------
        nmc : int
            number of realisations
        overwrite_existing: if True, existing parameter distributions will be kept, otherwise overwritten. Default: True

        Returns
        -------
        None.

        """
        
        
        print('Realising parameter sets wtih {} values'.format(self.settings['nmc']))
        for param in self.__parameters:
            s = param.realise(self.settings['nmc'], overwrite_existing = overwrite_existing)
            if s == 1:
                print('Parameter: {} ... OK'.format(param.name))
            elif s == -1:
                print('Parameter: {} ... ERROR'.format(param.name))
                
        
                
    def addResult(self, result):
        """
        adds a result to the simulation.

        Parameters
        ----------
        name : string
            name of the result
        results : array of numbers
            array of results. Length of vector must equal lenght of parameters.
            
        Returns
        -------
        None.
        """
        
        if not isinstance(result, Result):
            raise ValueError('Result is not an mcoo.Param object')
            
        #check if already exists
        if result.name in np.hstack([self.parameter_names, self.result_names]):
            raise ValueError('Element of that name already present')
            
        if not len(result.s) == self.settings['nmc']:
            raise Exception('Length of result does not match simulation number of cases')
            
        self.__results.append(result)
        
        #TODO: list result_namesx
        
        
    def __summary(self):
        """
        Statistical description of all simulation parameters and results

        Returns
        -------
        pandas.DataFrame with parameters and results as rows and properties as columns

        """
        #compose dataframe
        cols =  ['name', 'type', 'mean', 'std', 'min', 'max', 'P90', 'P50', 'P10']
        # index = [param.name for param in self.parameters] + [result.name for result in self.results]
        # sets = InputParamVal + ResultVal
        # types = ['parameter' if seti[0] in [par[0] for par in InputParamVal] else 'result' for seti in sets]
        s = pd.DataFrame(columns = cols)
        s.set_index('name', inplace = True)

        #add parameters
        for param in self.__parameters:
            s.loc[param.name, 'type'] = 'parameter'
            s.loc[param.name, 'mean'] = np.mean(param.s)
            s.loc[param.name, 'std'] = np.std(param.s)
            s.loc[param.name, 'min'] = min(param.s)
            s.loc[param.name, 'max'] = max(param.s)
            s.loc[param.name, 'P90'] = np.quantile(param.s, 0.1)
            s.loc[param.name, 'P50'] = np.quantile(param.s, 0.5)
            s.loc[param.name, 'P10'] = np.quantile(param.s, 0.9)
            
        #add results
        for result in self.__results:
            s.loc[result.name, 'type'] = 'result'
            s.loc[result.name, 'mean'] = np.mean(result.s)
            s.loc[result.name, 'std'] = np.std(result.s)
            s.loc[result.name, 'min'] = min(result.s)
            s.loc[result.name, 'max'] = max(result.s)
            s.loc[result.name, 'P90'] = np.quantile(result.s, 0.1)
            s.loc[result.name, 'P50'] = np.quantile(result.s, 0.5)
            s.loc[result.name, 'P10'] = np.quantile(result.s, 0.9)        

                         
        return s
    
    def dump(self):
        '''
        returns: pandas DataFrame containing all parameters and all results for each realisation
        '''
        colsp = [parami.name for parami in self.__parameters]
        colsr= [resi.name for resi in self.__results]
        
        dump = pd.DataFrame(columns = np.hstack([colsp, colsr]))
        
        for column in dump.columns:
            dump[column] = self[column].s
        return dump
    
    def convergence(self, plot = True):
        """
        evaluate the convergeence of a paramerter during a simulation. Convergence is indicated by the reduction of 
        the standard error of the running average.

        Parameters
        ----------
        plot : bool, optional
            show a plot of the evolution of all parameter means
        text : bool, optional
            describe the convergence of all parameters in text

        Returns
        -------
        None.

        """
        #compute running mean and standard error
        if self.__results is None:
            raise Exception('No results are defined to check convergence on.')
            
        print('Evaluating results')
        for result in self.__results:
            result.evaluateConvergence()
            #if text:
             #   print('Parameter: {}')
            
            
        #plot 
        if plot:
            n = math.ceil(len(self.__results) / 2)
            fig, ax = plt.subplots(n, 2, squeeze=True, sharex = True)
            ax = ax.flatten()
            fig.set_size_inches(2*5.51, n/2*5)  # 2*14 cm breit
        
            i = 0
        
            for result in self.__results:
        
                rsp = result.runningAverage + result.runningStandardError
                rsn = result.runningAverage - result.runningStandardError
        
                # plot result of each iteration
                ax[i].plot(result.s, alpha=0.4, color='grey')
                
                # plot running average
                ax[i].plot(result.runningAverage, color = 'blue')
                
                #plot area between -se and +se
                ax[i].fill_between(np.arange(0,len(result.s),1), rsn, rsp, facecolor = 'blue', alpha = 0.6)
                
                ax[i].set_title('Convergence of result: ' + result.name)
                fig.tight_layout()
                
                ax[i].set_xlabel('iteration')
                ax[i].set_ylabel('value')
        
                i = i+1
                
                if self.settings['saveplots']:
                    file = 'parameter convergence.png'
                    fig.savefig(Path(self.settings['savedir']) / 'qc and sensitivity' / file, bbox_inches = 'tight', dpi = 250)
                
    def sensitivity(self, pairplot = True, tornado_ciom = True):
        """
        

        Parameters
        ----------
        pairplot : boolean, optional
            plot a pairplot of all parameter / result combination. The default is True.
        tornado_ciom : boolean, optional
            plot a tornade diagram based on change in output mean correlation. The default is True.

        Returns
        -------
        Two pandas.DataFrames with preconfigured display style
        separmansr: pd.DataFrme containing Spearman's correlation coefficient between parameters and results.
        pearsonr:pd.DataFrme containing Pearson's correlation coefficient between parameters and results.

        """

        #get R² and linear fit parameters between all parameters and results
        self.pearsonr, self.spearmansr, self.coeff1, self.coeff2= self._correlate_r()
        
        #get change in output mean P10 and P90 matrixes
        self.ciom_p10, self.ciom_p90 = self._corelate_ciom()
        
        #Plot a Pairplot
        if pairplot:
             self._plot_pairplot()
             
        if tornado_ciom:
              self._plotTornado_ciom()
        
        #adjust display style and return pd.DataFrames for correlation coefficients
        #pandas display options
        pd.options.display.precision = 2
        cm = sns.color_palette("vlag", as_cmap=True)
        
        self.pearsonr.style.background_gradient(cmap=cm) 
        self.spearmansr.style.background_gradient(cmap=cm) 
        
        
        return self.spearmansr, self.pearsonr
    
    
    def correlate(self):
         """
         correlates every parameter to every result

         Returns
         -------
         r2 : pd.DataFrame (rows:parameters, cols: results, values: R²)
         spearmansr : pd.DataFrame (rows:parameters, cols: results, values: spearmans rho)
         coeff1 : pd.DataFrame (rows:parameters, cols: results, values: intercept)
         coeff2 : pd.DataFrame (rows:parameters, cols: results, values: slope)


         """
         r2 = []
         spearmansr = []
         pearsonr = []
         coeff1 = []
         coeff2 = []
         for param in self.__parameters:
            #fit parameter vs. result for each result (array of n(ResultVal) tupels)
            pfit_t = [np.polyfit(param.s, res.s, 1, full = True) for res in self.__results]
            
            
            #determine spearman rho
            spearmansr_t = np.array([stats.spearmanr(param.s, res.s)[0] for res in self.__results])
            pearsonr_t = np.array([stats.pearsonr(param.s, res.s)[0] for res in self.__results])
            #get linear regression coefficients
            
            coeff2_t = np.array([pfit[0][0] for pfit in pfit_t])
            coeff1_t = np.array([pfit[0][1] for pfit in pfit_t])
            
            
        
               
              #add to coeff1
            if isinstance(coeff1, np.ndarray):
                 coeff1 = np.vstack([coeff1, coeff1_t])
            else:
                 coeff1 = coeff1_t
             
            #add to coeff2
            if isinstance(coeff2, np.ndarray):
                 coeff2 = np.vstack([coeff2, coeff2_t])
            else:
                 coeff2 = coeff2_t
                 
            #add to spearmansr
            if isinstance(spearmansr, np.ndarray):
                 spearmansr = np.vstack([spearmansr, spearmansr_t])
            else:
                 spearmansr = spearmansr_t
    
            #add to pearsonr
            if isinstance(pearsonr, np.ndarray):
                 pearsonr = np.vstack([pearsonr, pearsonr_t])
            else:
                 pearsonr = pearsonr_t
               
               
               
               
               

         res_names = [res.name for res in self.__results]
         param_names = [param.name for param in self.__parameters]
         
         #convert r2, spearmansr, pearsonr, coeff1, coeff2 to pd.DataFrame 
         coeff1 = pd.DataFrame(coeff1, index = param_names, columns=(res_names)) 
         coeff2 = pd.DataFrame(coeff2, index = param_names, columns=(res_names))  
         spearmansr = pd.DataFrame(spearmansr, index = param_names, columns=(res_names))
         pearsonr = pd.DataFrame(pearsonr, index = param_names, columns=(res_names))   
           
         return pearsonr, spearmansr, coeff1, coeff2
     

    def compute_ciom(self):
         """
         
         correlates every result with every parameter regarding change in output mean for the P10 and P90+
         of the parameter.
         
         Parameters
         ----------

    
         Returns
         -------
         ciom_P10: Pandas dataframe with results as columns, parameters as rows, change in output mean of result for the lowest 10% of the result values
         ciom_P90: Pandas dataframe with results as columns, parameters as rows, change in output mean of result for the highest 10% of the result values
    
         """

    
         ciom_P10 = pd.DataFrame([], index = self.result_names, columns = self.parameter_names)
         ciom_P90 = pd.DataFrame([], index = self.result_names, columns = self.parameter_names)
         
         for result in self.__results:
              
              #merge result and parameters
              d = np.vstack([result.s, np.vstack([param.s for param in self.__parameters])]).T
              d = pd.DataFrame(d, columns = np.hstack(['res', self.parameter_names]))
              
              #sort by each parameter, compute result mean for Q10 and Q90
              mean_p10 = [np.mean(d.loc[(d[param.name] <= np.quantile(d[param.name], 0.9)), 'res']) for param in self.__parameters]
              
              mean_p90 = [np.mean(d.loc[(d[param.name] >= np.quantile(d[param.name], 0.1)), 'res']) for param in self.__parameters]
              
              ciom_P10.loc[ciom_P90.index == result.name, :] = mean_p90 - d['res'].mean()
              ciom_P90.loc[ciom_P10.index == result.name, :] = mean_p10 - d['res'].mean()
              
         return ciom_P10, ciom_P90
     
   
    def plot_pairplot(self, subset_par = None, subset_res = None, focus = True):
        """
        

        Parameters
        ----------
        subset_par : list, optional
            List of parameter names that should be plotted. If empty, all parameters are considered. The default is None.
        subset_res : list, optional
            ist of results names that should be plotted. If empty, all results are considered. The default is None.
        focus: narrow the x- and y lims of the plots to the 90% uncertainty intervals

        Returns
        -------
        None.

        """

        parameter_names = subset_par if subset_par is not None else self.parameter_names
        result_names = subset_res if subset_res is not None else self.result_names
        
        fig, ax = plt.subplots(len(parameter_names), len(result_names), sharex = 'col', sharey = 'row')
        fig.set_size_inches(2*5.51, len(parameter_names) * 2*5.51 / len(result_names))  # 2*14 cm breit
        
        if (len(parameter_names) <= 1) | (len(result_names) <= 1):
            ax = [ax]
        
        x = 0 #parameter rows
        y = 0 #result columns
        for param_name in parameter_names: #iterate through parameter rows
             x = 0 #first result column
             for res_name in result_names: #iterate through result columns
                 #plot data
                  
                  ax[y][x].scatter(x = self[res_name].s, y = self[param_name].s, label = str(x) + '/' + str(y), 
                                   facecolors = 'blue', edgecolors = 'none', s = 2)
                  #plot mean of both attributes
                  #first, fix x and ylim
                  ax[y][x].set_xlim(ax[y][x].get_xlim())
                  ax[y][x].set_ylim(ax[y][x].get_ylim())
                  ax[y][x].hlines(self[param_name].s.mean(), xmin = ax[y][x].get_xlim()[0], xmax = ax[y][x].get_xlim()[1], color = 'black', lw = 0.7)
                  ax[y][x].vlines(self[res_name].s.mean(), ymin = ax[y][x].get_ylim()[0], ymax = ax[y][x].get_ylim()[1], color = 'black', lw = 0.7)
                  
                  if y == len(parameter_names)-1:
                       ax[y][x].set_xlabel(self[res_name].name, rotation = 45)
                  if x == 0:
                       ax[y][x].set_ylabel(self[param_name].name)
                       
                   
                  
                  ax[y][x].grid(visible = True)
                  
                  if focus:
                    ax[y][x].set_xlim([np.quantile(self[res_name].s, 0.05), np.quantile(self[res_name].s, 0.95)]) 
                    ax[y][x].set_ylim([np.quantile(self[param_name].s, 0.05), np.quantile(self[param_name].s, 0.95)]) 
               
                  x += 1
             y += 1
             
        if self.settings['saveplots']:
            file = 'stairplot' + '.png'
            fig.savefig(Path(self.settings['savedir']) / 'qc and sensitivity' / file, bbox_inches = 'tight', dpi = 250)
            
    def plot_tornado(self):
        '''
        creates a tornado plot for each result, showing sensitivity on all parameters.
        Sensitivities are computed as change in output mean.
        '''
        ciom_p10, ciom_p90 = self.compute_ciom()
        
        #span from p10 to p90
        span = ((ciom_p90 - ciom_p10)
                .abs())
        
        for result in self.__results:
         
            fig, ax = plt.subplots()
            fig.set_size_inches(5.51,3.9)  # 2*14 cm breit
            
            
            ax.set_title(f"Result: {result.name} [{result.unit}]")
            #legenditems = [ 'base value', 'low', 'high']
            
            #sort ciom arrays by absolute value
            #ciom_p10t = ciom_p10.loc[ciom_p10.index == result.name].T.sort_values(by = result.name, key = abs, ascending = False)
            #ciom_p90t = ciom_p90.loc[ciom_p90.index == result.name].T.sort_values(by = result.name, key = abs, ascending = False)
            
            
            #sorting order descending from span p90 - p10
            sorting_order = (span
                     .loc[span.index == result.name]
                     .T
                     .assign(old_index = np.arange(span.shape[1]))
                     .sort_values(by = result.name, ascending = False)
                     .reset_index()
                     .sort_values(by = 'old_index', ascending = True)
                     .index
                     .to_numpy())
            
            ciom_p10t = (ciom_p10
                .loc[ciom_p10.index == result.name]
                .T
                .assign(sorting_order = sorting_order)
                .sort_values(by = 'sorting_order'))
            
                        
            ciom_p90t = (ciom_p90
                .loc[ciom_p90.index == result.name]
                .T
                .assign(sorting_order = sorting_order)
                .sort_values(by = 'sorting_order'))


            
            names = ciom_p10t.index
            
            ciom_p10t = np.squeeze(ciom_p10t[result.name].to_numpy())
            ciom_p90t = np.squeeze(ciom_p90t[result.name].to_numpy())
            
            base_value = result.s.mean()
            
            #compute left parameter for barh (P10)
            left = np.ones(len(ciom_p10t))
            left[ciom_p10t < 0] = base_value + ciom_p10t[ciom_p10t < 0]
            left[ciom_p10t >= 0] = base_value
            
            
            #plot ciom_p10
            ax.barh(y = np.flip(np.arange(0,stop = len(ciom_p10t))), width = abs(ciom_p10t) , left =  left, tick_label = names, alpha = 0.7, label = 'low')
            
            #compute left parameter for barh (P90)
            left = np.ones(len(ciom_p90t))
            left[ciom_p90t < 0] = base_value + ciom_p90t[ciom_p90t < 0]
            left[ciom_p90t >= 0] = base_value
            
            
            #plot ciom_p90
            ax.barh(y = np.flip(np.arange(0,stop = len(ciom_p90t))), width = abs(ciom_p90t) , left =  left,  tick_label = names, alpha = 0.7, label = 'high')     
            
            #compute and plot standard error of result in both directions
            std = np.std(result.s)
            ste = std / np.sqrt(self.settings['nmc'])
            ax.axvspan(base_value - ste, base_value + ste, color = 'white', alpha = 0.5, label = 'standard error')
            
            #plot baseline
            ax.vlines(x = base_value, ymin = ax.get_ylim()[0],  ymax = ax.get_ylim()[1], ls = '--', color = 'black', label = 'base value')
    
            plt.box(True)
            #plt.legend(frameon = True, loc = (1.04,0.5))
            plt.legend(frameon = True, loc = 4)
            
            plt.show()
            
            if self.settings['saveplots']:
                file = 'tornado' + result.name + '.png'
                fig.savefig(Path(self.settings['savedir']) / 'results' / file, bbox_inches = 'tight', dpi = 250)
            
          
    def showParameters(self, mode = 'sdh', showtable = True, showfig = True):
        """
        creates a plot for each parameter.

        Parameters
        ----------
        showtable: If True, shows summary table after each plot
        showfig: If True (Default), shows each plot
        mode : string, optional
            Plots the parameter. Default: 'd'. The submitted string can be a combination of the followiung characters:
            'd': distribution
            'h': historic data
            's': simulation data

        Returns
        -------
        None.

        """
        for param in self.__parameters:
            fig = param.plot(mode, showfig = showfig)
            
            if showtable:
                r = param.summary
                display(r)
                
            if self.settings['saveplots']:
                file = 'par_' + param.name + '.png'
                fig.savefig(Path(self.settings['savedir']) / 'parameters' / file, bbox_inches = 'tight', dpi = 250)
                
            
    def showResults(self, showtable = True, showfig = True):
        """
        creates a plot for each result
        
        Parameters
        --------
        showtable: If True, shows summary table after each plot
        showfig: If True (Default), shows each plot

        Returns
        -------
        None.

        """
        for result in self.__results:
            fig = result.plot(showfig = showfig)
            if showtable:
                display(result.summary)
                
            if self.settings['saveplots']:
                file = 'res_' + result.name + '.png'
                fig.savefig(Path(self.settings['savedir']) / 'results' / file, bbox_inches = 'tight', dpi = 250)
        
    def savesim(self):
        """
        

        Returns
        -------
        None.

        """
        file = self.settings['savedir'] / (self.name  + '.pickle')
        with open(file, 'wb') as f:
            pickle.dump(self, f, protocol=pickle.HIGHEST_PROTOCOL)
        

def runningAverage(array):
     '''
     

     Parameters
     ----------
     array : np.array
          DESCRIPTION: array of numbers on which to compute the running average
     Returns
     -------
     ra : TYPE
          running average

     '''
     ra = np.zeros(len(array))

     i = 0
     while i+1 <= len(array):
          
          ra[i] = np.mean(array[0:i+1])
          i = i+1

     return ra

def runningStandardError(array):
     """
     computes a running standard error (std / sqrt(n))

     Parameters
     ----------
     array : np.array
          list in correct order for which to calculate the running quantile
     quantile : float
          quantile to compute

     Returns
     -------
     array of sane length as input with the running standard error values

     """
     rs = np.zeros(len(array))

     i = 1
     while i+1 <= len(array):
          
          rs[i] = np.std(array[0:i+1]) / np.sqrt(i)
          i = i+1

     return rs
        
        

        
        
        
